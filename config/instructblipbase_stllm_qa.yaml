model:
  arch: st_llm_hf
  model_type: instructblip_vicuna0_btadapter
  use_grad_checkpoint: True
  max_txt_len: 256
  end_sym: "###"
  video_input: "all"
  llama_model: '/path/to/vicuna-7b-v1.1'
  ckpt: '/Path/to/instruct_blip_vicuna7b_trimmed.pth'
  q_former_model: '/Path/to/instruct_blip_vicuna7b_trimmed.pth'
  qformer_text_input: True
  freeze_LLM: False
  use_mask : True
  mvm_decode: True

datasets:
  caption_videochatgpt:
    num_frames: 16
    #video_reader_type: 'rawframe'
  classification_k710:
    num_frames: 16
  classification_ssv2:
    num_frames: 16
  reasoning_next_qa:
    num_frames: 16
  reasoning_clevrer_qa:
    num_frames: 16
  reasoning_clevrer_mc:
    num_frames: 16
  vqa_webvid_qa:
    num_frames: 16

run:
  task: video_text_it
  bf16: True
  tf32: False
  output_dir: "./stllm/output/instructblipbase_stllm_qa"
  num_train_epochs: 2
  dataloader_num_workers: 4
  per_device_train_batch_size: 16
  per_device_eval_batch_size: 16
  gradient_accumulation_steps: 1
  evaluation_strategy: "no"
  learning_rate: 2e-5
  weight_decay: 0.
  warmup_ratio: 0.03
  lr_scheduler_type: 'cosine'
  logging_steps: 50
  model_max_length: 1024
  #save_steps: 10000 
  save_strategy: "epoch" 
  save_total_limit: 1
  deepspeed: 'stllm/train/zero3.json'